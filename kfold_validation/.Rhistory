#k-fold validation full model without education spending
frame<-read.csv("LifeExpPlus.csv", row.names = 1)
povinc<-frame$Inequity*frame$PovertyRate
frame$povinc=povinc
sol<-lm(AvgLifeExp ~logGDP+Inequity +PovertyRate+povinc, data=frame) #note that
# in this function, the data is specified as coming from the object frame, so $ sign notation is not necessary
print(sol) #model output
anova_sol<-anova(sol)
anova_sol #anova table for this model
6587/192
library(DAAG)
fit<-lm(AvgLifeExp ~logGDP+Inequity +PovertyRate+povinc, data=frame)
cvoutput<-cv.lm(data = frame, fit, m=5,  printit = TRUE) #perform k-fold validation
# Define data frame with the problem variables
df <- data.frame(demand=c(217,600,511,700,552,681,872,895,1087),
price= c(5,4.75,4.5,4.25,4,3.75,3.5,3.25,3))
# Define data frame with the problem variables
df <- data.frame(demand=c(217,600,511,700,552,681,872,895,1087),
price= c(5,4.75,4.5,4.25,4,3.75,3.5,3.25,3))
print(df)
# Run linear regression
model <- lm(demand~price,data=df) #create linear model of demand as a function of price
# Print results
summary(model)
# Plot data and linear fit
plot(x = df$price, y = df$demand, col = 'blue',
pch = 16, cex = 1.3, main = 'Demand by Price'  ) # plot demand by price
abline(model,col='red',lw=3) #plots the best linear best fit on top of an existing plot
# Compute confidence intervals with new data
new = data.frame(price=c(3,4)) #the new prices we want predictions for
# Compute confidence intervals with new data
new = data.frame(price=c(3,4)) #the new prices we want predictions for
# Compute prediction intervals with new data
predict(model,newdata=new,interval='prediction',level=0.9) #predict the mean values of y
# Compute confidence intervals with new data
new = data.frame(price=c(3,4)) #the new prices we want predictions for
# Compute prediction intervals with new data
predict(model,newdata=new,interval='prediction',level=0.9) #predict the mean values of y
predict(model,newdata=new,interval='confidence',level=0.9) # calculates our confidence
## level for the mean value of y. here, interval = 'confidence specifies that we want to calculate the
## confidence interval
print(model)
df
#Part one
# Define data frame with the problem variables
df <- data.frame(demand=c(217,600,511,700,552,681,872,895,1087),
price= c(5,4.75,4.5,4.25,4,3.75,3.5,3.25,3))
print(df)
# Run linear regression
model <- lm(demand~price,data=df) #create linear model of demand as a function of price
# Print results
summary(model)
# Plot data and linear fit
plot(x = df$price, y = df$demand, col = 'blue',
pch = 16, cex = 1.3, main = 'Demand by Price'  ) # plot demand by price
model
# Print results
summary(model)
deviance(model)
sum(resid(model)^2)
86773**(1/2)
(86773**(1/2))/9
(86773.16/9)**1/2
4**1/2
9**1/2
9^(1/2)
16^(1/2)
(86773.16/9)^1/2
(86773.16/9)^(1/2)
(86773.16/7)^(1/2)
deviance(model)
sum(resid(model)^2)
sd(df$price)
(1/7*deviance(model))^(1/2)/3/sd(df$price)
mean(df$price)
(1/7*deviance(model))^(1/2)/3*(1+16/var(df$price))^(1/2)
var(df$price)
sd(df$price)^(1/2)
var(df$price)^(1/2)
(1/7*sum(resid(model)^2))^(1/2)/3*(1+16/var(df$price))^(1/2)
# confidence interval for a price 4 and 3
predict(model, newdata = 3, interval = 'confidence')
# confidence interval for a price 4 and 3
predict(model, newdata = c(3), interval = 'confidence')
# Compute prediction intervals with new data
predict(model,newdata=new,interval='prediction',level=0.9) #predict the mean values of y
predict(model,newdata=new,interval='confidence',level=0.9) # calculates our confidence
901.7934-457.0955
1264.9084-769.7138
749.7574-609.1315
1146.9617-887.6605
#Part one
# Define data frame with the problem variables
df <- data.frame(demand=c(217,600,511,700,552,681,872,895,1087),
price= c(5,4.75,4.5,4.25,4,3.75,3.5,3.25,3))
print(df)
# Run linear regression
model <- lm(demand~price,data=df) #create linear model of demand as a function of price
# Plot data and linear fit
plot(x = df$price, y = df$demand, col = 'blue',
pch = 16, cex = 1.3, main = 'Demand by Price'  ) # plot demand by price
# Compute confidence intervals with new data
new = data.frame(price=c(3,4)) #the new prices we want predictions for
# Compute prediction intervals with new data
predict(model,newdata=new,interval='prediction',level=0.9) #predict the mean values of y
predict(model,newdata=new,interval='confidence',level=0.9) # calculates our confidence
#anova
anova_model<-anova(model)
anova_model
summary(anova_model)
86773/9
86773/7
#Part one
# Define data frame with the problem variables
df <- data.frame(demand=c(217,600,511,700,552,681,872,895,1087),
price= c(5,4.75,4.5,4.25,4,3.75,3.5,3.25,3))
# Run linear regression
model <- lm(demand~price,data=df) #create linear model of demand as a function of price
# Compute confidence intervals with new data
new = data.frame(price=c(3,4)) #the new prices we want predictions for
# Compute prediction intervals with new data
predict(model,newdata=new,interval='prediction',level=0.9) #predict the mean values of y
predict(model,newdata=new,interval='confidence',level=0.9) # calculates our confidence
#anova
anova_model<-anova(model)
summary(anova_model)
anova_model
86773/7
anova_model.tss
tss = var(df$demand)/9
tss
1 - 86773/7150.698
tss = var(df$demand)*9
tss
1 - 86773/579206.5
1-86773/tss
#PRESS
PRESS(model)
#PRESS
install.packages("qpcR")
library("qpcR")
library("Matrix")
PRESS(model)
press <- PRESS(model)
summary(press)
summary(anova_model)
anova_model
press <- PRESS(model)
summary(press)
press
press$residuals
press$stat
press
press$residuals
press$residuals^2
sum(press$residuals^2)
model
# Print results
summary(model)
# k-fold cross validation
cvoutput <- cv.lm(data = df, model, m=2,  printit = TRUE) #perform k-fold validation
#Part one
# Define data frame with the problem variables
df <- data.frame(demand=c(217,600,511,700,552,681,872,895,1087),
price= c(5,4.75,4.5,4.25,4,3.75,3.5,3.25,3))
print(df)
# Run linear regression
model <- lm(demand~price,data=df) #create linear model of demand as a function of price
# Run linear regression
model <- lm(demand~price,data=df) #create linear model of demand as a function of price
# k-fold cross validation
cvoutput <- cv.lm(data = df, model, m=2,  printit = TRUE) #perform k-fold validation
# k-fold cross validation
cvoutput <- cv.lm(data = df, model, m=2,  printit = TRUE) #perform k-fold validation
# Run linear regression
model <- lm(demand~price,data=df) #create linear model of demand as a function of price
# Run linear regression
model <- lm(demand~price,data=df) #create linear model of demand as a function of price
# k-fold cross validation
cvoutput <- cv.lm(data = df, model, m=2,  printit = TRUE) #perform k-fold validation
cvoutput
# part2
library(leaps) # for best subsets
frame<-read.csv("ElectionData.csv", row.names=1)
frame<-read.csv("/Users/chiaentsai/Desktop/Data_Analytics/Data_Analytics_Code/hw5_part2/ElectionData.csv", row.names=1)
# Backward elimination
step(lm(Clinton ~ . -countystate - fips - US regions , data=frame),
frame.columns
col(frame)
# Backward elimination
step(lm(Clinton ~ . -countystate - fips - US.regions , data=frame),
direction="backward")
frame
ncol(frame)
# Backward elimination
step(lm(Clinton ~ . - fips - US.regions , data=frame),
direction="backward")
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=5)
choices<-summary(models)  #Data window gives BIC, Adj R2
print(choices$which)
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=10)
print(choices$which)
# Read in the data
frame<-read.csv("LifeExpPlus.csv", row.names=1)
frame$povinc<-frame$Inequity*frame$PovertyRate # create interaction term
models<-regsubsets(AvgLifeExp~logGDP+Inequity+PovertyRate+EducSpending+povinc,
data=frame, nvmax=5)
choices<-summary(models)  #Data window gives BIC, Adj R2
print(choices$which)
print(choices$adjr2)
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=10)
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=10)
# part2
library(leaps) # for best subsets
frame<-read.csv("/Users/chiaentsai/Desktop/Data_Analytics/Data_Analytics_Code/hw5_part2/ElectionData.csv", row.names=1)
# part2
library(leaps) # for best subsets
frame<-read.csv("/Users/chiaentsai/Desktop/Data_Analytics/Data_Analytics_Code/hw5_part2/ElectionData.csv", row.names=1)
# part2
library(leaps) # for best subsets
frame<-read.csv("/Users/chiaentsai/Desktop/Data_Analytics/Data_Analytics_Code/hw5_part2/ElectionData.csv", row.names=1)
# Best subset selection
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=10)
choices<-summary(models)  #Data window gives BIC, Adj R2
# Best subset selection
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=5)
choices<-summary(models)  #Data window gives BIC, Adj R2
print(choices$which)
print(choices$adjr2)
print(choices$bic)
choices
print(choices$adjr2)
# Best subset selection
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=10)
choices<-summary(models)  #Data window gives BIC, Adj R2
print(choices$adjr2)
# Best subset selection
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=15)
# Best subset selection
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=15)
choices<-summary(models)  #Data window gives BIC, Adj R2
print(choices$adjr2)
# Best subset selection
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=18)
choices<-summary(models)  #Data window gives BIC, Adj R2
print(choices$adjr2)
# part2
library(leaps) # for best subsets
frame<-read.csv("/Users/chiaentsai/Desktop/Data_Analytics/Data_Analytics_Code/hw5_part2/ElectionData.csv", row.names=1)
# Best subset selection
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=10)
choices<-summary(models)  #Data window gives BIC, Adj R2
choices
print(choices$adjr2)
nclol(frame)
ncol(frame)
print(choices$bic)
# part2
library(leaps) # for best subsets
frame<-read.csv("/Users/chiaentsai/Desktop/Data_Analytics/Data_Analytics_Code/hw5_part2/ElectionData.csv",
row.names=1)
# Best subset selection
models<-regsubsets(Clinton ~ . - fips - US.regions , data=frame, nvmax=10)
choices<-summary(models)  #Data window gives BIC, Adj R2
print(choices$adjr2)
print(choices$bic)
choices$cp
step(lm(Clinton ~ . - fips - US.regions, data=frame), direction="forward")
step(lm(Clinton ~ . - fips - US.regions, data=frame), direction="both")
a <- step(lm(Clinton ~ . - fips - US.regions, data=frame), direction="both")
a$coefficients
frame<-read.csv("/Users/chiaentsai/Desktop/Data_Analytics/Data_Analytics_Code/hw5_part2/ElectionData.csv",
row.names=1)
# Stepwise Selection
a <- step(lm(Clinton ~ . - fips - US.regions, data=frame), direction="both")
a$coefficients
a$adjr2
a$bic
a$residuals
a$effects
a$fitted.values
a$coefficients
a$rank
a$fitted.values
a$assign
a$residuals
(a$residuals)^2
sum((a$residuals)^2)
#rebuild the model using Dummyvar
frame<-read.csv("LifeExpPlus.csv", row.names = 1)
cor(frame, method="pearson")
plot(x=frame$Inequity, y=frame$DummyVar)
model<-lm(formula =frame$AvgLifeExp ~frame$logGDP+frame$Inequity + frame$PovertyRate+DummyVar, data=frame)
#drop DummyVar
model<-lm(formula =frame$AvgLifeExp ~frame$logGDP+frame$Inequity + frame$PovertyRate, data=frame)
#rebuild the model using Dummyvar
frame<-read.csv("LifeExpPlus.csv", row.names = 1)
cor(frame, method="pearson")
plot(x=frame$Inequity, y=frame$DummyVar)
model<-lm(formula =frame$AvgLifeExp ~frame$logGDP+frame$Inequity + frame$PovertyRate+DummyVar, data=frame)
#notice p-values for Inequality and
#DummyVar. Remember p-values are marginal tests
summary(model)
#drop DummyVar
model<-lm(formula =frame$AvgLifeExp ~frame$logGDP+frame$Inequity + frame$PovertyRate, data=frame)
summary(model)
#drop Inequality
model<-lm(formula =frame$AvgLifeExp ~frame$logGDP+frame$PovertyRate+DummyVar, data=frame)
summary(model)
library(car) # Load the library car so you can calculate the vif
vif(lm(frame$AvgLifeExp ~frame$logGDP+frame$Inequity + frame$PovertyRate+DummyVar, data=frame)) #calculate the VIF of the model with the Dummy variable
plot(x=frame$Inequity, y=frame$DummyVar)
#rebuild the model using Dummyvar
frame<-read.csv("LifeExpPlus.csv", row.names = 1)
model<-lm(formula =frame$AvgLifeExp ~frame$logGDP+frame$Inequity + frame$PovertyRate+DummyVar, data=frame)
#notice p-values for Inequality and
#DummyVar. Remember p-values are marginal tests
summary(model)
#drop DummyVar
model<-lm(formula =frame$AvgLifeExp ~frame$logGDP+frame$Inequity + frame$PovertyRate, data=frame)
summary(model)
#drop Inequality
model<-lm(formula =frame$AvgLifeExp ~frame$logGDP+frame$PovertyRate+DummyVar, data=frame)
summary(model)
#rebuild the model using Dummyvar
frame<-read.csv("LifeExpPlus.csv", row.names = 1)
cor(frame, method="pearson")
model<-lm(formula =frame$AvgLifeExp ~frame$logGDP+frame$Inequity + frame$PovertyRate+DummyVar, data=frame)
#notice p-values for Inequality and
#DummyVar. Remember p-values are marginal tests
summary(model)
#drop DummyVar
model<-lm(formula =frame$AvgLifeExp ~frame$logGDP+frame$Inequity + frame$PovertyRate, data=frame)
summary(model)
#drop Inequality
model<-lm(formula =frame$AvgLifeExp ~frame$logGDP+frame$PovertyRate+DummyVar, data=frame)
summary(model)
library(pscl)
# Read in data
df <- read.csv("AcquisitionAcceptance.csv")
# Read in data
df <- read.csv("/Users/chiaentsai/Desktop/Data_Analytics/Data_Analytics_Code/hw5_part5/AcquisitionAcceptance.csv")
col(df)
colnames(df)
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price125
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price110
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price100
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price90
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price75
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price75
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price100
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Read in data
df <- read.csv("/Users/chiaentsai/Desktop/Data_Analytics/Data_Analytics_Code/hw5_part5/AcquisitionAcceptance.csv")
colnames(df)
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price125
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Compute McFadden Pseudo R-Squared for Model Evaluation
pR2(model)['McFadden']
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price110
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Compute McFadden Pseudo R-Squared for Model Evaluation
pR2(model)['McFadden']
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price90
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Compute McFadden Pseudo R-Squared for Model Evaluation
pR2(model)['McFadden']
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price75
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Compute McFadden Pseudo R-Squared for Model Evaluation
pR2(model)['McFadden']
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Compute McFadden Pseudo R-Squared for Model Evaluation
pR2(model)['McFadden']
# Create interaction term between After and a Price variable of your choosing
# by replacing YOURVARHERE with the desired variable name
df$Interaction <- df$After * df$Price75
# Construct logistic regression with interaction term
model <- glm(Accept~Distance+HomeTenure+Education345+After+Price75+Price90+Price110+Price125+Interaction,
family=binomial(link='logit'),data=df)
# Examine statistical significance of model coefficients
summary(model)
# Compute McFadden Pseudo R-Squared for Model Evaluation
pR2(model)['McFadden']
